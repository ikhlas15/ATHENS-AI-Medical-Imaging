{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ikhlas15/ATHENS-AI-Medical-Imaging/blob/main/H14_project_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Notebook 14: Final Project Template for Medical Imaging AI**\n",
        "\n",
        "### **Course**: Artificial Intelligence in Medical Imaging: From Fundamentals to Applications\n",
        "\n",
        "***\n",
        "\n",
        "## **1. Introduction**\n",
        "\n",
        "Congratulations on reaching the final hands-on session of the course! You have learned all the core components of building a medical imaging AI model, from data loading to explainability. This notebook serves as a **capstone project template**. It brings together all the best practices we've discussed into a single, organized, and reusable structure.\n",
        "\n",
        "The goal of this template is to provide you with a solid foundation for your own medical AI projects. A well-structured project is easier to develop, debug, reproduce, and share with collaborators.\n",
        "\n",
        "#### **What this template provides:**\n",
        "*   A logical **project structure** for organizing your code, data, and results.\n",
        "*   Reusable, modular code for:\n",
        "    *   Data loading and preprocessing (`Dataset`, `DataLoader`).\n",
        "    *   Model definition.\n",
        "    *   Training and validation loops.\n",
        "    *   Saving and loading model checkpoints.\n",
        "    *   Evaluation and visualization.\n",
        "*   A complete, end-to-end workflow that you can adapt to your specific problem, whether it's classification or segmentation.\n",
        "\n",
        "***\n",
        "\n",
        "## **2. The Anatomy of a Medical AI Project**\n",
        "\n",
        "A professional AI project is more than just a single script. It's a well-organized collection of files and folders, each with a specific purpose. This organization makes your work scalable and reproducible.\n",
        "\n",
        "Here is a standard project layout. In Google Colab, you can create these directories in `/content/` or in your mounted Google Drive.\n",
        "\n",
        "```\n",
        "/my_medical_ai_project/\n",
        "|\n",
        "|--- ðŸ“‚ data/\n",
        "|    |--- ðŸ“‚ train/\n",
        "|    |    |--- ðŸ“‚ images/\n",
        "|    |    |--- ðŸ“‚ masks/\n",
        "|    |--- ðŸ“‚ val/\n",
        "|    |--- ðŸ“‚ test/\n",
        "|\n",
        "|--- ðŸ“‚ src/\n",
        "|    |--- ðŸ“„ datasets.py       # Custom Dataset classes\n",
        "|    |--- ðŸ“„ models.py         # Model architectures (e.g., UNet, ResNet)\n",
        "|    |--- ðŸ“„ engine.py         # Training and validation loops\n",
        "|    |--- ðŸ“„ utils.py          # Helper functions (e.g., seeding, plotting)\n",
        "|    |--- ðŸ“„ config.py         # Configuration settings (hyperparameters)\n",
        "|\n",
        "|--- ðŸ“‚ notebooks/\n",
        "|    |--- ðŸ“„ 01_data_exploration.ipynb\n",
        "|    |--- ðŸ“„ 02_model_training.ipynb\n",
        "|\n",
        "|--- ðŸ“œ train.py              # Main script to run training\n",
        "|--- ðŸ“œ evaluate.py           # Script to run evaluation on a saved model\n",
        "|\n",
        "|--- ðŸ“‚ outputs/\n",
        "|    |--- ðŸ“‚ checkpoints/     # Saved model weights\n",
        "|    |--- ðŸ“‚ logs/            # TensorBoard logs or metrics\n",
        "|\n",
        "`--- ðŸ“œ requirements.txt      # Project dependencies\n",
        "```\n",
        "For this template notebook, we will define all the necessary components in one place for simplicity. In a real project, you would split them into the separate `.py` files shown above.\n",
        "\n",
        "***\n",
        "\n",
        "## **3. Step 1: Configuration**\n",
        "\n",
        "A best practice is to manage all your hyperparameters and settings in one place. This makes experiments easy to track and modify.\n"
      ],
      "metadata": {
        "id": "SaaJd_WBALOI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6x9LHyiZ_uL1"
      },
      "outputs": [],
      "source": [
        "# --- Configuration Settings ---\n",
        "import torch\n",
        "class Config:\n",
        "    # Data settings\n",
        "    DATA_DIR = \"/content/data/pneumonia/\"\n",
        "    IMAGE_SIZE = 224\n",
        "\n",
        "    # Model settings\n",
        "    MODEL_NAME = \"resnet18\"\n",
        "    NUM_CLASSES = 2\n",
        "    PRETRAINED = True\n",
        "\n",
        "    # Training settings\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    BATCH_SIZE = 32\n",
        "    LEARNING_RATE = 1e-4\n",
        "    NUM_EPOCHS = 4\n",
        "\n",
        "    # Paths\n",
        "    CHECKPOINT_PATH = \"/content/outputs/checkpoints/best_model.pth\"\n",
        "\n",
        "# Instantiate the config\n",
        "config = Config()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## **4. Step 2: Setup and Utilities**\n",
        "\n",
        "This section contains our standard setup code: installing packages, importing libraries, and defining helper functions.\n"
      ],
      "metadata": {
        "id": "rgC2BJGsATlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install required packages\n",
        "#!pip install -q torch torchvision medmnist scikit-learn seaborn captum\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "from medmnist import PneumoniaMNIST\n",
        "from tqdm import tqdm\n",
        "\n",
        "#  Seeding for Reproducibility\n",
        "def set_seed(seed=42):\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True   # ensures same output each run\n",
        "    torch.backends.cudnn.benchmark = False      # disables cuDNN autotuner for reproducibility\n",
        "\n",
        "# Hint: Call the function with a fixed seed value\n",
        "set_seed(_____)\n",
        "\n",
        "# Hint: Print the device (CPU or GPU). Where is DEVICE stored?\n",
        "print(f\"Using device: {_____.DEVICE}\")\n"
      ],
      "metadata": {
        "id": "sfPG8ue-ARnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## **5. Step 3: Data Loading Module**\n",
        "\n",
        "Here, we define our `Dataset` and `DataLoader`. This code would typically live in `src/datasets.py`."
      ],
      "metadata": {
        "id": "OagfRnmtArcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Data Transformations ---\n",
        "data_transforms = {\n",
        "    'train': T.Compose([\n",
        "        # Hint: Resize to the image size defined in config\n",
        "        T.Resize((config.IMAGE_SIZE, config.IMAGE_SIZE)),\n",
        "\n",
        "        # Hint: Data augmentation (random flip)\n",
        "        T.RandomHorizontalFlip(p=_____),\n",
        "\n",
        "        # Hint: Small random rotation (degrees)\n",
        "        T.RandomRotation(degrees=_____),\n",
        "\n",
        "        T.ToTensor(),\n",
        "\n",
        "        # Hint: Normalize grayscale image: mean=0.5, std=0.5\n",
        "        T.Normalize(mean=[_____], std=[_____])\n",
        "    ]),\n",
        "\n",
        "    'val': T.Compose([\n",
        "        T.Resize((config.IMAGE_SIZE, config.IMAGE_SIZE)),\n",
        "        T.ToTensor(),\n",
        "        # Hint: Same normalization for validation\n",
        "        T.Normalize(mean=[_____], std=[_____])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# --- Datasets ---\n",
        "# Hint: Load PneumoniaMNIST training split\n",
        "train_dataset = PneumoniaMNIST(\n",
        "    split='train',\n",
        "    transform=data_transforms['_____'],\n",
        "    download=True\n",
        ")\n",
        "\n",
        "# Hint: Load PneumoniaMNIST validation split\n",
        "val_dataset = PneumoniaMNIST(\n",
        "    split='_____',\n",
        "    transform=data_transforms['_____'],\n",
        "    download=True\n",
        ")\n",
        "\n",
        "# --- DataLoaders ---\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=_____.BATCH_SIZE,   # Hint: batch size from config\n",
        "    shuffle=_____                  # Hint: should training data be shuffled?\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=_____.BATCH_SIZE,   # Hint: same batch size\n",
        "    shuffle=_____                  # Hint: validation is NOT shuffled\n",
        ")\n",
        "\n",
        "print(f\"Data loaded: {len(train_dataset)} training images, {len(val_dataset)} validation images.\")\n"
      ],
      "metadata": {
        "id": "efzv1wDxApN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## **6. Step 4: Model Definition Module**\n",
        "\n",
        "This defines our model architecture. In a real project, this would be in `src/models.py`.\n"
      ],
      "metadata": {
        "id": "pEWYk948A1jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Build Model ---\n",
        "def build_model(model_name, num_classes, pretrained=True):\n",
        "\n",
        "    if model_name == \"resnet18\":\n",
        "\n",
        "        # Hint: Load a pretrained ResNet18 if requested\n",
        "        if pretrained:\n",
        "            model = models.resnet18(weights=\"_____\")\n",
        "        else:\n",
        "            model = models.resnet18()\n",
        "\n",
        "        # Hint: Replace first conv layer for 1-channel (grayscale) input\n",
        "        model.conv1 = nn.Conv2d(\n",
        "            in_channels=_____,   # should be 1\n",
        "            out_channels=_____,  # should be 64\n",
        "            kernel_size=7,\n",
        "            stride=2,\n",
        "            padding=3,\n",
        "            bias=False\n",
        "        )\n",
        "\n",
        "        # Hint: Grab number of features from final FC layer\n",
        "        num_ftrs = model.fc._____\n",
        "\n",
        "        # Hint: Replace classifier to match number of classes\n",
        "        model.fc = nn.Linear(\n",
        "            in_features=_____,   # same as num_ftrs\n",
        "            out_features=_____   # same as num_classes\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        # Hint: Only resnet18 is implemented right now\n",
        "        raise NotImplementedError(f\"Model {model_name} not implemented.\")\n",
        "\n",
        "    # Hint: Send model to device (CPU/GPU)\n",
        "    return model.to(config.______)\n",
        "\n",
        "\n",
        "# --- Build model using config settings ---\n",
        "model = build_model(\n",
        "    model_name=_____.MODEL_NAME,     # Hint: e.g., \"resnet18\"\n",
        "    num_classes=_____.NUM_CLASSES,   # Hint: 2 for pneumonia dataset\n",
        "    pretrained=_____.PRETRAINED      # Hint: True or False\n",
        ")\n"
      ],
      "metadata": {
        "id": "WqTV-aklA4Nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## **7. Step 5: Training Engine Module**\n",
        "\n",
        "This contains our core training and validation logic, along with checkpointing functions. This would live in `src/engine.py` and `src/utils.py`.\n"
      ],
      "metadata": {
        "id": "k9_BHmZkBuBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Loss and Optimizer ---\n",
        "# Hint: Use CrossEntropyLoss for classification\n",
        "criterion = nn.__________()\n",
        "\n",
        "# Hint: Use Adam optimizer with learning rate from config\n",
        "optimizer = optim.Adam(\n",
        "    model.__________(),      # model parameters\n",
        "    lr=_____.LEARNING_RATE   # learning rate\n",
        ")\n",
        "\n",
        "\n",
        "# --- Training and Validation Loops ---\n",
        "def train_one_epoch(model, data_loader, criterion, optimizer, device):\n",
        "    model.__________()   # Hint: set model to training mode\n",
        "\n",
        "    total_loss, total_correct = 0.0, 0\n",
        "\n",
        "    for images, labels in data_loader:\n",
        "        # Hint: Move data to device (CPU/GPU)\n",
        "        images  = images.to(__________)\n",
        "        labels  = labels.to(__________).squeeze().long()\n",
        "\n",
        "        optimizer.__________()  # Hint: reset gradients\n",
        "\n",
        "        # Hint: forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Hint: compute loss\n",
        "        loss = criterion(__________, _________)\n",
        "\n",
        "        # Hint: backward pass\n",
        "        loss.__________()\n",
        "\n",
        "        # Hint: update weights\n",
        "        optimizer.__________()\n",
        "\n",
        "        total_loss += loss.item() * images.size(0)\n",
        "\n",
        "        # Hint: predicted class = argmax\n",
        "        total_correct += (torch.argmax(outputs, dim=_____) == labels).sum().item()\n",
        "\n",
        "    # Hint: divide by total dataset size\n",
        "    return total_loss / len(data_loader.dataset), total_correct / len(data_loader.dataset)\n",
        "\n",
        "\n",
        "\n",
        "def validate(model, data_loader, criterion, device):\n",
        "    model.__________()   # Hint: evaluation mode\n",
        "\n",
        "    total_loss, total_correct = 0.0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images = images.to(__________)\n",
        "            labels = labels.to(__________).squeeze().long()\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            total_correct += (torch.argmax(outputs, dim=_____) == labels).sum().item()\n",
        "\n",
        "    return total_loss / len(data_loader.dataset), total_correct / len(data_loader.dataset)\n",
        "\n",
        "\n",
        "\n",
        "# --- Checkpointing ---\n",
        "def save_checkpoint(model, optimizer, epoch, path):\n",
        "\n",
        "    # Hint: Create directory if it does not exist\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "\n",
        "    # Hint: Save epoch, model weights, optimizer state\n",
        "    torch.save({\n",
        "        'epoch': _________,\n",
        "        'model_state_dict': model.__________(),\n",
        "        'optimizer_state_dict': optimizer.__________(),\n",
        "    }, path)\n"
      ],
      "metadata": {
        "id": "WKneHTPOBq61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## **8. Step 6: Main Training Script**\n",
        "\n",
        "This is the main executable part of the project that ties everything together. In a full project, this would be `train.py`.\n"
      ],
      "metadata": {
        "id": "NNW5GqpbB7lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Training History ---\n",
        "history = {\n",
        "    'train_loss': [],\n",
        "    'train_acc':  [],\n",
        "    'val_loss':   [],\n",
        "    'val_acc':    []\n",
        "}\n",
        "\n",
        "best_val_acc = 0.0\n",
        "\n",
        "print(\"--- Starting Training ---\")\n",
        "\n",
        "for epoch in tqdm(range(config.__________)):   # Hint: number of epochs from config\n",
        "\n",
        "    # Hint: call training function\n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        config.__________    # device\n",
        "    )\n",
        "\n",
        "    # Hint: call validation function\n",
        "    val_loss, val_acc = validate(\n",
        "        model,\n",
        "        val_loader,\n",
        "        criterion,\n",
        "        config.__________     # device\n",
        "    )\n",
        "\n",
        "    # Store history\n",
        "    history['train_loss'].append(__________)\n",
        "    history['train_acc'].append(__________)\n",
        "    history['val_loss'].append(__________)\n",
        "    history['val_acc'].append(__________)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{config.NUM_EPOCHS}] | \"\n",
        "          f\"Train Loss: {__________:.4f}, Train Acc: {__________:.4f} | \"\n",
        "          f\"Val Loss: {__________:.4f}, Val Acc: {__________:.4f}\")\n",
        "\n",
        "    # --- Save the best model ---\n",
        "    # Hint: Check if validation accuracy improved\n",
        "    if val_acc > __________:\n",
        "        best_val_acc = val_acc\n",
        "        print(f\\\"New best model found! Saving checkpoint to {config.__________}\\\")\n",
        "\n",
        "        # Hint: Save model\n",
        "        save_checkpoint(\n",
        "            model,\n",
        "            optimizer,\n",
        "            epoch,\n",
        "            config.__________      # checkpoint path\n",
        "        )\n",
        "\n",
        "print(\"--- Training Finished ---\")\n"
      ],
      "metadata": {
        "id": "SLF6x2FjB8kO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## **9. Step 7: Evaluation and Visualization**\n",
        "\n",
        "After training, load your best model and perform a thorough evaluation. This part would typically be in `evaluate.py` or an evaluation notebook.\n"
      ],
      "metadata": {
        "id": "SlE4enJ-CGPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load the best model for evaluation ---\n",
        "# Hint: Normally you'd reload from disk using torch.load. Here we assume the model is already loaded.\n",
        "\n",
        "model.eval()\n",
        "all_labels = []\n",
        "all_predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        # Hint: Move images to device\n",
        "        images = images.to(config.__________)\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Hint: Convert model outputs to predicted class indices\n",
        "        predictions = torch.argmax(outputs, dim=______)\n",
        "\n",
        "        # Hint: Convert tensors to numpy arrays before extending the lists\n",
        "        all_labels.extend(labels.__________())\n",
        "        all_predictions.extend(predictions.cpu().__________())\n",
        "\n",
        "# --- Final Metrics and Confusion Matrix ---\n",
        "# Hint: Compute final accuracy using sklearn\n",
        "final_accuracy = accuracy_score(__________, __________)\n",
        "print(f\"\\nFinal Validation Accuracy of Best Model: {final_accuracy:.4f}\")\n",
        "\n",
        "# Hint: Compute confusion matrix\n",
        "cm = confusion_matrix(__________, __________)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    cmap='Oranges',\n",
        "    xticklabels=['Normal', 'Pneumonia'],\n",
        "    yticklabels=['Normal', 'Pneumonia']\n",
        ")\n",
        "plt.title(\"Final Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n",
        "\n",
        "# --- Plot Training Curves ---\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# --- Loss plots ---\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history['__________'], label='Train Loss')       # Hint: fill history key\n",
        "plt.plot(history['__________'], label='Validation Loss')  # Hint: fill history key\n",
        "plt.title(\"Loss Curves\")\n",
        "plt.legend()\n",
        "\n",
        "# --- Accuracy plots ---\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history['__________'], label='Train Accuracy')       # Hint: fill history key\n",
        "plt.plot(history['__________'], label='Validation Accuracy')  # Hint: fill history key\n",
        "plt.title(\"Accuracy Curves\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7TmpmtXGCF_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## **10. Summary and Next Steps**\n",
        "\n",
        "This notebook provides a complete, professional template for tackling a medical imaging AI project. By separating concernsâ€”data, model, training, and evaluationâ€”you create a codebase that is clean, reusable, and easy to modify for new experiments.\n",
        "\n",
        "**How to use this template for your own project:**\n",
        "1.  **Define Your Problem:** Is it classification or segmentation? What is your data source?\n",
        "2.  **Gather and Organize Your Data:** Place your images and labels into the `data/` directory structure.\n",
        "3.  **Adapt the `Dataset` Class:** Modify the `MedicalImageDataset` class in Step 5 to load your specific file types (e.g., NIfTI, DICOM).\n",
        "4.  **Choose and Define Your Model:** Select an architecture in Step 6. Will you use a ResNet, a U-Net, or something custom?\n",
        "5.  **Configure Your Experiment:** Adjust the settings in the `Config` class in Step 3.\n",
        "6.  **Run and Iterate:** Execute the training and evaluation steps. Analyze the results, and then go back to tweak your model, data augmentations, or hyperparameters.\n",
        "\n",
        "Good luck with your future projects! This structured approach will serve you well as you build innovative and impactful AI solutions for medicine.\n"
      ],
      "metadata": {
        "id": "qnz6ydNUCR9J"
      }
    }
  ]
}